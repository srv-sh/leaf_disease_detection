{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.54-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m783.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in ./leaf_env/lib/python3.11/site-packages (from roboflow) (2025.1.31)\n",
      "Collecting idna==3.7\n",
      "  Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./leaf_env/lib/python3.11/site-packages (from roboflow) (2.2.3)\n",
      "Collecting opencv-python-headless==4.10.0.84\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting Pillow>=7.1.2\n",
      "  Using cached pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Requirement already satisfied: python-dateutil in ./leaf_env/lib/python3.11/site-packages (from roboflow) (2.9.0.post0)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in ./leaf_env/lib/python3.11/site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in ./leaf_env/lib/python3.11/site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in ./leaf_env/lib/python3.11/site-packages (from roboflow) (2.3.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in ./leaf_env/lib/python3.11/site-packages (from roboflow) (4.67.1)\n",
      "Collecting PyYAML>=5.3.1\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
      "Collecting requests-toolbelt\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Collecting filetype\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./leaf_env/lib/python3.11/site-packages (from matplotlib->roboflow) (24.2)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./leaf_env/lib/python3.11/site-packages (from requests->roboflow) (3.4.1)\n",
      "Installing collected packages: filetype, PyYAML, python-dotenv, pyparsing, Pillow, opencv-python-headless, kiwisolver, idna, fonttools, cycler, contourpy, matplotlib, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "Successfully installed Pillow-11.1.0 PyYAML-6.0.2 contourpy-1.3.1 cycler-0.12.1 filetype-1.2.0 fonttools-4.56.0 idna-3.7 kiwisolver-1.4.8 matplotlib-3.10.0 opencv-python-headless-4.10.0.84 pyparsing-3.2.1 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.54\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in leaf_detection-1 to yolov12:: 100%|██████████| 8518/8518 [00:03<00:00, 2222.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to leaf_detection-1 in yolov12:: 100%|██████████| 162/162 [00:00<00:00, 17780.38it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"9MoGKNjyxriFivoPOl2m\")\n",
    "project = rf.workspace(\"signaturedetection-im4xu\").project(\"leaf_detection-fcyc2\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov12\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sourav/workplace/leaf_disease_detection/leaf_env/lib/python3.11/site-packages/albumentations/core/validation.py:58: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping and augmentation completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import albumentations as A\n",
    "\n",
    "# Define paths\n",
    "dataset_path = \"/home/sourav/workplace/leaf_disease_detection/leaf_detection-1\"  # Update this with your dataset path\n",
    "output_path = \"/home/sourav/workplace/leaf_disease_detection/cropped_data\"  # Update this with your desired output path\n",
    "dataset_types = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "# Define augmentation pipelines\n",
    "augmentations = [\n",
    "    A.Compose([\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.RandomBrightnessContrast(p=1.0),\n",
    "        A.Rotate(limit=30, p=1.0),\n",
    "        A.GaussNoise(p=1.0)\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=20, p=1.0),\n",
    "        A.Blur(blur_limit=3, p=1.0)\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.CLAHE(p=1.0),\n",
    "        A.ColorJitter(p=1.0),\n",
    "        A.RandomGamma(p=1.0)\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Function to create class-wise directories\n",
    "def create_class_dirs(base_path, class_ids):\n",
    "    for dataset_type in dataset_types:\n",
    "        for class_id in class_ids:\n",
    "            class_dir = os.path.join(base_path, dataset_type, str(class_id))\n",
    "            os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "# Function to extract and augment objects\n",
    "def extract_objects():\n",
    "    class_ids = set()\n",
    "    \n",
    "    for dataset_type in dataset_types:\n",
    "        images_path = os.path.join(dataset_path, dataset_type, \"images\")\n",
    "        labels_path = os.path.join(dataset_path, dataset_type, \"labels\")\n",
    "        \n",
    "        for label_file in os.listdir(labels_path):\n",
    "            if not label_file.endswith(\".txt\"):\n",
    "                continue\n",
    "            \n",
    "            image_file = label_file.replace(\".txt\", \".jpg\")  # Change to .png if needed\n",
    "            image_path = os.path.join(images_path, image_file)\n",
    "            label_path = os.path.join(labels_path, label_file)\n",
    "            \n",
    "            if not os.path.exists(image_path):\n",
    "                continue\n",
    "            \n",
    "            image = cv2.imread(image_path)\n",
    "            h, w, _ = image.shape\n",
    "            \n",
    "            with open(label_path, \"r\") as file:\n",
    "                lines = file.readlines()\n",
    "                \n",
    "                for idx, line in enumerate(lines):\n",
    "                    parts = line.strip().split()\n",
    "                    class_id = int(parts[0])\n",
    "                    class_ids.add(class_id)\n",
    "                    x_center, y_center, box_width, box_height = map(float, parts[1:])\n",
    "                    \n",
    "                    # Convert YOLO format to pixel values\n",
    "                    x_min = int((x_center - box_width / 2) * w)\n",
    "                    y_min = int((y_center - box_height / 2) * h)\n",
    "                    x_max = int((x_center + box_width / 2) * w)\n",
    "                    y_max = int((y_center + box_height / 2) * h)\n",
    "                    \n",
    "                    cropped_object = image[y_min:y_max, x_min:x_max]\n",
    "                    \n",
    "                    if cropped_object.size == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    output_dir = os.path.join(output_path, dataset_type, str(class_id))\n",
    "                    os.makedirs(output_dir, exist_ok=True)\n",
    "                    \n",
    "                    output_filename = f\"{image_file.split('.')[0]}_{idx}.jpg\"\n",
    "                    output_filepath = os.path.join(output_dir, output_filename)\n",
    "                    cv2.imwrite(output_filepath, cropped_object)\n",
    "                    \n",
    "                    # Apply multiple augmentations only for class_id 0\n",
    "                    if class_id == 0:\n",
    "                        for aug_idx, aug in enumerate(augmentations):\n",
    "                            augmented = aug(image=cropped_object)\n",
    "                            augmented_image = augmented[\"image\"]\n",
    "                            \n",
    "                            aug_output_filename = f\"{image_file.split('.')[0]}_{idx}_aug{aug_idx}.jpg\"\n",
    "                            aug_output_filepath = os.path.join(output_dir, aug_output_filename)\n",
    "                            cv2.imwrite(aug_output_filepath, augmented_image)\n",
    "                    \n",
    "    print(\"Cropping and augmentation completed!\")\n",
    "    create_class_dirs(output_path, class_ids)\n",
    "\n",
    "# Run extraction and augmentation\n",
    "extract_objects()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/home/sourav/workplace/leaf_disease_detection/cropped_data/train/0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
